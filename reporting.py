# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.ticker as mtick
import matplotlib.dates as mdates
import seaborn as sns
import yfinance as yf
import openpyxl
import warnings

warnings.filterwarnings('ignore')

def generate_report(results, data):
    """
    1:1è¿˜åŸåŸå§‹ä»£ç çš„å®Œæ•´æŠ¥å‘ŠåŠŸèƒ½
    åŒ…æ‹¬æŒä»“å»ºè®®æ±‡æ€»ã€æ€§èƒ½æŒ‡æ ‡è®¡ç®—ã€å¤æ‚å›¾è¡¨ç»˜åˆ¶å’ŒExcelå¯¼å‡º
    """
    
    # ä»resultså’Œdataä¸­æå–æ‰€éœ€å‚æ•°
    portfolio_value_over_time = results['portfolio_value_over_time']
    weights_df = results['weights_df']
    winning_periods = results['winning_periods']
    total_periods = results['total_periods']
    portfolio_log = results['portfolio_log']
    
    # ä»dataä¸­æå–å‚æ•°
    rf_rate_annual_decimal = data['rf_rate_annual_decimal']
    start_date = data['start_date']
    end_date = data['end_date']
    
    # å¯¼å…¥é…ç½®æ¨¡å—
    import config
    
    # --- è¾“å‡ºæ‰€æœ‰æŒä»“å»ºè®®æ±‡æ€» ---
    print("\n" + "="*80)
    print("ğŸ“Š é£é™©è°ƒæ•´åŠ¨é‡ç­–ç•¥å»ºè®®æ±‡æ€» ğŸ“Š")
    print("="*80)

    if portfolio_log:
        # è·å–æœ€æ–°çš„å»ºè®®
        latest_decision_date = max(portfolio_log.keys())
        latest_recommendation = portfolio_log[latest_decision_date]
        latest_holdings = latest_recommendation[latest_recommendation > 0].sort_values(ascending=False)
        
        print(f"\nğŸ”¥ æœ€æ–°é£é™©è°ƒæ•´åŠ¨é‡å»ºè®® ({latest_decision_date.date()}):")
        if not latest_holdings.empty:
            for ticker, weight in latest_holdings.items():
                print(f"   {ticker}: {weight:.2%}")
            
            total_weight = latest_holdings.sum()
            if config.apply_ndx_short_hedge:
                print(f"\n   å¤šå¤´æ€»æƒé‡: {total_weight:.2%}")
                print(f"   NDXåšç©ºæƒé‡: {config.ndx_short_ratio:.2%}")
                cash_weight = 1.0 - total_weight - config.ndx_short_ratio
                if cash_weight > 0.01:
                    print(f"   ç°é‡‘æƒé‡: {cash_weight:.2%}")
            else:
                cash_weight = 1.0 - total_weight
                if cash_weight > 0.01:
                    print(f"   ç°é‡‘æƒé‡: {cash_weight:.2%}")
        else:
            print("   æ¨è: å…¨éƒ¨ç°é‡‘")
        
        # æ˜¾ç¤ºå†å²å»ºè®®æ•°é‡
        print(f"\nğŸ“ˆ æ€»å…±ç”Ÿæˆäº† {len(portfolio_log)} æœŸè°ƒä»“å»ºè®®")
        
        # ä¿å­˜å»ºè®®åˆ°å•ç‹¬çš„æ–‡ä»¶
        try:
            recommendations_df = pd.DataFrame(portfolio_log).T
            recommendations_df = recommendations_df[recommendations_df.sum(axis=1) > 0]  # åªä¿å­˜æœ‰æŒä»“çš„æœŸé—´
            
            # åªä¿å­˜æœ‰æƒé‡çš„åˆ—
            non_zero_columns = (recommendations_df != 0).any(axis=0)
            recommendations_summary = recommendations_df.loc[:, non_zero_columns]
            
            factor_suffix = "_Enhanced" if config.use_enhanced_factor else "_Original"
            hedge_suffix = f"_NDXShort{int(config.ndx_short_ratio*100)}pct" if config.apply_ndx_short_hedge else ""
            recommendations_filename = f'Risk_Adjusted_Momentum_Recommendations_{config.weighting_method}{factor_suffix}{hedge_suffix}.xlsx'
            
            with pd.ExcelWriter(recommendations_filename, engine='openpyxl') as writer:
                recommendations_summary.to_excel(writer, sheet_name='Risk_Adjusted_Recommendations', index_label='Decision_Date')
                
                # åˆ›å»ºä¸€ä¸ªæ ¼å¼åŒ–çš„å»ºè®®è¡¨
                formatted_recommendations = recommendations_summary.copy()
                for col in formatted_recommendations.columns:
                    formatted_recommendations[col] = formatted_recommendations[col].apply(lambda x: f"{x:.2%}" if x > 0 else "")
                formatted_recommendations.to_excel(writer, sheet_name='Formatted_Recommendations', index_label='Decision_Date')
            
            print(f"ğŸ’¾ é£é™©è°ƒæ•´åŠ¨é‡æŒä»“å»ºè®®å·²ä¿å­˜è‡³: {recommendations_filename}")
            
        except Exception as e:
            print(f"ä¿å­˜å»ºè®®æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    print("="*80)

    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„å‡€å€¼æ•°æ®
    if portfolio_value_over_time.empty:
        print("\né”™è¯¯ï¼šå›æµ‹åæŠ•èµ„ç»„åˆå‡€å€¼åºåˆ—ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œç»©æ•ˆåˆ†æã€‚")
        return
    
    print("\nPortfolio Value (Tail):")
    print(portfolio_value_over_time.tail())
    print("\nTarget Weights Log (Tail):")
    print(weights_df.tail())

    # --- æ­¥é©Ÿ 7: è¨ˆç®—ä¸¦å±•ç¤ºç¸¾æ•ˆæŒ‡æ¨™ ---
    print("\næ­¥é©Ÿ 7: è¨ˆç®—ä¸¦å±•ç¤ºç¸¾æ•ˆæŒ‡æ¨™...")

    # --- æº–å‚™è¨ˆç®— ---
    # è¨ˆç®—æ¯æ—¥æ”¶ç›Šç‡ (å¾å›æ¸¬çµæœçš„æ·¨å€¼åºåˆ—è¨ˆç®—)
    analysis_daily_returns = portfolio_value_over_time.pct_change().dropna()
    print("Daily returns calculated from portfolio value.")
    
    # --- æ–°å¢: ä¸‹è¼‰åŸºæº–æ•¸æ“šä¸¦è¨ˆç®—Alpha, Beta, Information Ratio ---
    alpha, beta, information_ratio = np.nan, np.nan, np.nan
    try:
        print("æ­£åœ¨ä¸‹è¼‰åŸºæº–æŒ‡æ•¸æ•¸æ“š (^NDX) ä»¥è¨ˆç®— Alpha/Beta...")
        benchmark_returns = yf.download('^NDX', start=start_date, end=end_date, progress=False)['Close'].pct_change()

        # åˆä½µå’Œå°é½Šæ”¶ç›Šç‡æ•¸æ“š
        merged_returns = pd.concat([analysis_daily_returns, benchmark_returns], axis=1, join='inner')
        merged_returns.columns = ['portfolio', 'benchmark']
        
        if merged_returns.empty:
            print("è­¦å‘Š: ç­–ç•¥å’ŒåŸºæº–æŒ‡æ•¸æ²’æœ‰é‡ç–Šçš„äº¤æ˜“æ—¥ï¼Œç„¡æ³•è¨ˆç®— Alpha/Betaã€‚")
        else:
            # å°é½Šç„¡é¢¨éšªåˆ©ç‡æ•¸æ“š
            aligned_rf_rate = rf_rate_annual_decimal.reindex(merged_returns.index).ffill()
            daily_rf_rate = (1 + aligned_rf_rate)**(1/config.trading_days_per_year) - 1
            
            # è¨ˆç®—è¶…é¡æ”¶ç›Š (ç›¸å°æ–¼ç„¡é¢¨éšªåˆ©ç‡)
            portfolio_excess_returns = merged_returns['portfolio'] - daily_rf_rate
            benchmark_excess_returns = merged_returns['benchmark'] - daily_rf_rate

            # è¨ˆç®—Beta
            covariance = portfolio_excess_returns.cov(benchmark_excess_returns)
            benchmark_variance = benchmark_excess_returns.var()
            beta = covariance / benchmark_variance if benchmark_variance != 0 else np.nan
            
            # è¨ˆç®—Alpha (å¹´åŒ–)
            alpha_daily = portfolio_excess_returns.mean() - beta * benchmark_excess_returns.mean()
            alpha = alpha_daily * config.trading_days_per_year

            # è¨ˆç®—Information Ratio
            active_returns = merged_returns['portfolio'] - merged_returns['benchmark']
            tracking_error = active_returns.std() * np.sqrt(config.trading_days_per_year)
            
            # ä½¿ç”¨ç­–ç•¥çš„å¹´åŒ–æ”¶ç›Šç‡å’ŒåŸºæº–çš„å¹´åŒ–æ”¶ç›Šç‡
            # ç¢ºä¿ä½¿ç”¨ç›¸åŒçš„æ™‚é–“æ®µè¨ˆç®—å¹´åŒ–æ”¶ç›Š
            aligned_years = (merged_returns.index[-1] - merged_returns.index[0]).days / 365.25
            if aligned_years > 0:
                annualized_return_for_ir = (1 + merged_returns['portfolio']).prod()**(1/aligned_years) - 1
                annualized_benchmark_return_for_ir = (1 + merged_returns['benchmark']).prod()**(1/aligned_years) - 1
                information_ratio = (annualized_return_for_ir - annualized_benchmark_return_for_ir) / tracking_error if tracking_error > 0 else np.nan
            else:
                information_ratio = np.nan
            
            print(f"æŒ‡æ¨™è¨ˆç®—å®Œæˆ: Alpha={alpha:.4f}, Beta={beta:.3f}, IR={information_ratio:.3f}")

    except Exception as e:
        print(f"è¨ˆç®— Alpha/Beta/IR æ™‚å‡ºéŒ¯: {e}")
        alpha, beta, information_ratio = np.nan, np.nan, np.nan
    
    # --- æº–å‚™ç›¸é—œåƒæ•¸ ---
    start_val = portfolio_value_over_time.iloc[0]
    end_val = portfolio_value_over_time.iloc[-1]
    start_dt = portfolio_value_over_time.index[0]
    end_dt = portfolio_value_over_time.index[-1]
    years_elapsed = (end_dt - start_dt).days / 365.25

    # --- è¨ˆç®—æŒ‡æ¨™ ---
    cumulative_return = (end_val / start_val) - 1

    if years_elapsed <= 0:
        annualized_return = 0
    else:
        annualized_return = (end_val / start_val) ** (1 / years_elapsed) - 1

    annualized_volatility = analysis_daily_returns.std() * np.sqrt(config.trading_days_per_year)

    # å°é½Šç„¡é¢¨éšªåˆ©ç‡æ•¸æ“šåˆ°ç­–ç•¥çš„æ¯æ—¥æ”¶ç›Šç‡æ—¥æœŸ
    aligned_rf_rate = rf_rate_annual_decimal.reindex(analysis_daily_returns.index).ffill()
    average_annual_risk_free_rate = aligned_rf_rate.mean()

    if annualized_volatility == 0 or np.isnan(annualized_volatility):
        sharpe_ratio = np.nan
    else:
        sharpe_ratio = (annualized_return - average_annual_risk_free_rate) / annualized_volatility

    rolling_max = portfolio_value_over_time.cummax()
    daily_drawdown = (portfolio_value_over_time / rolling_max) - 1
    max_drawdown = daily_drawdown.min()

    if max_drawdown == 0 or np.isnan(max_drawdown):
        calmar_ratio = np.nan
    else:
        calmar_ratio = annualized_return / abs(max_drawdown)

    # Calculate Win Rate
    if total_periods > 0:
        win_rate = winning_periods / total_periods
    else:
        win_rate = np.nan

    # --- æ•´ç†ä¸¦å±•ç¤ºçµæœ ---
    performance_summary = {
        "æ¬Šé‡æ–¹æ³•": config.weighting_method.replace('_', ' ').title(),
        "å›æ¸¬æœŸé–“": f"{start_dt.strftime('%Y-%m-%d')} åˆ° {end_dt.strftime('%Y-%m-%d')}" if pd.notna(start_dt) else "N/A",
        "æœŸåˆæ·¨å€¼": f"{start_val:.4f}" if pd.notna(start_val) else "N/A",
        "æœŸæœ«æ·¨å€¼": f"{end_val:.4f}" if pd.notna(end_val) else "N/A",
        "ç´¯ç©å ±é…¬ç‡": f"{cumulative_return:.2%}" if pd.notna(cumulative_return) else "N/A",
        "å¹´åŒ–å ±é…¬ç‡ (CAGR)": f"{annualized_return:.2%}" if pd.notna(annualized_return) else "N/A",
        "å¹´åŒ–æ³¢å‹•ç‡": f"{annualized_volatility:.2%}" if pd.notna(annualized_volatility) else "N/A",
        "å¹³å‡å¹´åŒ–ç„¡é¢¨éšªåˆ©ç‡": f"{average_annual_risk_free_rate:.2%}" if pd.notna(average_annual_risk_free_rate) else "N/A",
        "å¹´åŒ–å¤æ™®æ¯”ç‡": f"{sharpe_ratio:.3f}" if pd.notna(sharpe_ratio) else "N/A",
        "æœ€å¤§å›æ’¤ (MDD)": f"{max_drawdown:.2%}" if pd.notna(max_drawdown) else "N/A",
        "Calmar æ¯”ç‡": f"{calmar_ratio:.3f}" if pd.notna(calmar_ratio) else "N/A",
        "å‹ç‡ (æŒ‰èª¿å€‰æœŸ)": f"{win_rate:.2%}" if pd.notna(win_rate) else "N/A",
        "Alpha (å¹´åŒ–, vs. ^NDX)": f"{alpha:.2%}" if pd.notna(alpha) else "N/A",
        "Beta (vs. ^NDX)": f"{beta:.3f}" if pd.notna(beta) else "N/A",
        "ä¿¡æ¯æ¯”ç‡ (vs. ^NDX)": f"{information_ratio:.3f}" if pd.notna(information_ratio) else "N/A"
    }

    if config.apply_downside_frequency_filter:
        performance_summary["ä¸‹è¡Œæ³¢å‹•é »ç‡éæ¿¾"] = f"å•Ÿç”¨ (éå»{config.downside_frequency_lookback_days}å¤© < {config.downside_frequency_threshold:.0%})"
    else:
        performance_summary["ä¸‹è¡Œæ³¢å‹•é »ç‡éæ¿¾"] = "æœªå•Ÿç”¨"

    if config.apply_volume_factor:
        performance_summary["æˆäº¤é‡å› å­èª¿æ•´"] = f"å•Ÿç”¨ (é•·å›çœ‹{config.volume_long_lookback_days}å¤©, å¹…åº¦{config.volume_multiplier_floor}-{config.volume_multiplier_cap})"
    else:
        performance_summary["æˆäº¤é‡å› å­èª¿æ•´"] = "æœªå•Ÿç”¨"

    if config.apply_stop_loss:
        performance_summary["å€‹è‚¡æ­¢ææ©Ÿåˆ¶"] = f"å•Ÿç”¨ ({config.stop_loss_pct:.0%})"
    else:
        performance_summary["å€‹è‚¡æ­¢ææ©Ÿåˆ¶"] = "æœªå•Ÿç”¨"

    if config.apply_ndx_short_hedge:
        performance_summary["NDXåšç©ºå°æ²–"] = f"å•Ÿç”¨ ({config.ndx_short_ratio:.0%} åšç©º^NDX)"
    else:
        performance_summary["NDXåšç©ºå°æ²–"] = "æœªå•Ÿç”¨"

    print("\n--- ç­–ç•¥ç¸¾æ•ˆç¸½çµ ---")
    for key, value in performance_summary.items():
        print(f"{key:<25}: {value}")
    print("----------------------")

    # --- ç¹ªè£½ç¸¾æ•ˆåœ–è¡¨ ---
    try:
        # ä¸‹è¼‰æ¨™æ™®500å’Œç´æ–¯é”å…‹100çš„æ•¸æ“š
        print("\nä¸‹è¼‰åŸºæº–æŒ‡æ•¸æ•¸æ“š...")
        benchmark_data_download = yf.download(['^SPX', '^NDX'], start=start_date, end=end_date)
        
        # Try to get 'Adj Close', fallback to 'Close'
        try:
            benchmark_data = benchmark_data_download['Adj Close']
        except KeyError:
            print("Warning: 'Adj Close' not found for benchmark data, trying 'Close'.")
            benchmark_data = benchmark_data_download['Close']
            
        benchmark_data = benchmark_data.reindex(portfolio_value_over_time.index).ffill()
        print("\nDebug: benchmark_data after reindex and ffill:")
        print(benchmark_data.head())
        print(benchmark_data.tail())
        print("Debug: NaN counts in benchmark_data:")
        print(benchmark_data.isna().sum())

        # è¨ˆç®—åŸºæº–æŒ‡æ•¸çš„æ”¶ç›Šç‡
        benchmark_returns = benchmark_data.pct_change()
        benchmark_cumulative = (1 + benchmark_returns).cumprod()
        print("\nDebug: benchmark_cumulative before normalization (and after initial cumprod):")
        print(benchmark_cumulative.head())

        # The first row of pct_change() is NaN, so the first row of cumprod() will also be NaN.
        # We set the first valid row of benchmark_cumulative to 1, as it's our starting point.
        
        # Find the first valid index for each column (benchmark)
        for col in benchmark_cumulative.columns:
            first_valid_idx = benchmark_cumulative[col].first_valid_index()
            if first_valid_idx is not None:
                # Set the first value to 1 (our normalized base)
                benchmark_cumulative.loc[first_valid_idx, col] = 1.0
            else:
                # If a column is all NaN (should not happen if benchmark_data was fine), fill with 1 to prevent errors.
                benchmark_cumulative[col] = 1.0 
        
        # Forward fill any NaNs that might have been at the beginning (e.g. if pct_change had multiple leading NaNs due to market holidays)
        benchmark_cumulative = benchmark_cumulative.ffill()

        print("\nDebug: benchmark_cumulative after setting first valid to 1 and ffill:")
        print(benchmark_cumulative.head())
        print(benchmark_cumulative.tail())
        print("Debug: NaN counts in benchmark_cumulative:")
        print(benchmark_cumulative.isna().sum())
        
        # è¨­ç½®ä¸­æ–‡å­—é«”å’Œæ¨£å¼
        try:
            plt.style.use('seaborn-v0_8-whitegrid') # Try a more specific seaborn style
        except:
            print("Warning: 'seaborn-v0_8-whitegrid' style not found. Using default style.")
            
        plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
        plt.rcParams['axes.unicode_minus'] = False
        plt.rcParams['font.size'] = 11 # Base font size
        plt.rcParams['axes.titlesize'] = 14
        plt.rcParams['axes.labelsize'] = 12
        
        # å‰µå»ºå­åœ–ï¼Œä½¿ç”¨GridSpecä¾†æ›´å¥½åœ°æ§åˆ¶ä½ˆå±€
        fig = plt.figure(figsize=(20, 14)) # Larger figure for better spacing
        fig.suptitle('é¢¨éšªèª¿æ•´å‹•é‡ç­–ç•¥ç¸¾æ•ˆåˆ†æ', fontsize=18, y=0.98)
        
        # Create a more balanced GridSpec layout with custom spacing
        gs = plt.GridSpec(2, 2, height_ratios=[1.2, 1], width_ratios=[1.2, 1], 
                         hspace=0.25, wspace=0.25)
        
        # 1. æŠ•è³‡çµ„åˆåƒ¹å€¼åœ– (Top-Left)
        ax1 = fig.add_subplot(gs[0, 0])
        ax1.plot(portfolio_value_over_time.index, portfolio_value_over_time, 
                 label='ç­–ç•¥çµ„åˆ', color='#1f77b4', linewidth=2.5)
        ax1.plot(benchmark_cumulative.index, benchmark_cumulative['^SPX'], 
                 label='æ¨™æ™®500', color='#2ca02c', linewidth=1.8, alpha=0.8)
        ax1.plot(benchmark_cumulative.index, benchmark_cumulative['^NDX'], 
                 label='ç´æ–¯é”å…‹100', color='#ff7f0e', linewidth=1.8, alpha=0.8)
        
        ax1.set_title('ç­–ç•¥ç¸¾æ•ˆå°æ¯”', fontsize=15, pad=15, fontweight='bold')
        ax1.set_ylabel('ç´¯ç©æ”¶ç›Š (èµ·å§‹å€¼=1)', fontsize=12)
        ax1.grid(True, linestyle='--', alpha=0.6)
        ax1.legend(loc='upper left', frameon=True, facecolor='white', framealpha=0.9, fontsize=11)
        
        # æ·»åŠ å¹´åŒ–æ”¶ç›Šç‡æ¨™ç±¤
        strategy_annual_return = (portfolio_value_over_time.iloc[-1] ** (252/len(portfolio_value_over_time)) - 1) * 100
        spx_annual_return = (benchmark_cumulative['^SPX'].iloc[-1] ** (252/len(benchmark_cumulative)) - 1) * 100
        ndx_annual_return = (benchmark_cumulative['^NDX'].iloc[-1] ** (252/len(benchmark_cumulative)) - 1) * 100
        
        # Add a box for the returns
        props = dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor='lightgray')
        textstr = f'å¹´åŒ–æ”¶ç›Šç‡:\nç­–ç•¥: {strategy_annual_return:.1f}%\næ¨™æ™®500: {spx_annual_return:.1f}%\nç´æ–¯é”å…‹100: {ndx_annual_return:.1f}%'
        ax1.text(0.02, 0.85, textstr, transform=ax1.transAxes, fontsize=11,
                verticalalignment='top', bbox=props)
        
        # Format x-axis to show years
        ax1.xaxis.set_major_locator(mdates.YearLocator())
        ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # 2. å›æ’¤åœ– (Top-Right)
        ax2 = fig.add_subplot(gs[0, 1])
        strategy_drawdown = (portfolio_value_over_time / portfolio_value_over_time.cummax() - 1) * 100
        spx_drawdown = (benchmark_cumulative['^SPX'] / benchmark_cumulative['^SPX'].cummax() - 1) * 100
        ndx_drawdown = (benchmark_cumulative['^NDX'] / benchmark_cumulative['^NDX'].cummax() - 1) * 100
        
        ax2.fill_between(strategy_drawdown.index, strategy_drawdown, 0, 
                         color='#1f77b4', alpha=0.4, label='ç­–ç•¥å›æ’¤')
        ax2.fill_between(spx_drawdown.index, spx_drawdown, 0, 
                         color='#2ca02c', alpha=0.3, label='æ¨™æ™®500å›æ’¤')
        ax2.fill_between(ndx_drawdown.index, ndx_drawdown, 0, 
                         color='#ff7f0e', alpha=0.3, label='ç´æ–¯é”å…‹100å›æ’¤')
        
        ax2.set_title('æœ€å¤§å›æ’¤æ¯”è¼ƒ', fontsize=15, pad=15, fontweight='bold')
        ax2.set_ylabel('å›æ’¤ (%)', fontsize=12)
        ax2.grid(True, linestyle='--', alpha=0.6)
        ax2.legend(loc='lower left', frameon=True, facecolor='white', framealpha=0.9, fontsize=11)
        
        # Format x-axis to show years
        ax2.xaxis.set_major_locator(mdates.YearLocator())
        ax2.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        
        # Add max drawdown info
        max_strategy_dd = strategy_drawdown.min()
        max_spx_dd = spx_drawdown.min()
        max_ndx_dd = ndx_drawdown.min()
        
        dd_textstr = f'æœ€å¤§å›æ’¤:\nç­–ç•¥: {max_strategy_dd:.1f}%\næ¨™æ™®500: {max_spx_dd:.1f}%\nç´æ–¯é”å…‹100: {max_ndx_dd:.1f}%'
        ax2.text(0.02, 0.15, dd_textstr, transform=ax2.transAxes, fontsize=11,
                verticalalignment='bottom', bbox=props)
        
        # 3. æœˆåº¦æ”¶ç›Šç†±åŠ›åœ– (Bottom-Left)
        ax3 = fig.add_subplot(gs[1, 0])
        monthly_returns_series = portfolio_value_over_time.resample('M').last().pct_change().dropna()

        if not monthly_returns_series.empty:
            if not isinstance(monthly_returns_series.index, pd.DatetimeIndex):
                monthly_returns_series.index = pd.to_datetime(monthly_returns_series.index)

            if isinstance(monthly_returns_series.index, pd.DatetimeIndex):
                monthly_returns_df = monthly_returns_series.to_frame(name='Returns')
                monthly_returns_df['Year'] = monthly_returns_df.index.year
                monthly_returns_df['Month'] = monthly_returns_df.index.month
                monthly_returns_pivot = monthly_returns_df.pivot(index='Year', columns='Month', values='Returns')
                
                month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
                # Ensure all 12 months are columns, fill missing with NaN, then assign names
                monthly_returns_pivot = monthly_returns_pivot.reindex(columns=range(1,13))
                monthly_returns_pivot.columns = month_names[:len(monthly_returns_pivot.columns)]
                
                # Use a more distinct colormap for better visibility
                cmap = sns.diverging_palette(10, 133, as_cmap=True)
                
                sns.heatmap(monthly_returns_pivot, 
                            annot=True,
                            fmt='.1%',
                            cmap=cmap,
                            center=0,
                            cbar_kws={'label': 'æœˆåº¦æ”¶ç›Šç‡', 'shrink': 0.8},
                            linewidths=1,
                            linecolor='white',
                            ax=ax3)
                
                # Rotate x-axis labels for better readability
                plt.setp(ax3.get_xticklabels(), rotation=0, ha='center')
                plt.setp(ax3.get_yticklabels(), rotation=0)
                
            else:
                print("Warning: Could not process monthly_returns.index as DatetimeIndex for heatmap.")
                ax3.text(0.5, 0.5, 'æœˆåº¦æ”¶ç›Šæ•¸æ“šç´¢å¼•éŒ¯èª¤', horizontalalignment='center', verticalalignment='center', transform=ax3.transAxes)
        else:
            ax3.text(0.5, 0.5, 'æœˆåº¦æ”¶ç›Šæ•¸æ“šä¸è¶³', 
                     horizontalalignment='center',
                     verticalalignment='center',
                     transform=ax3.transAxes)
        
        ax3.set_title('æœˆåº¦æ”¶ç›Šç†±åŠ›åœ–', fontsize=15, pad=15, fontweight='bold')
        
        # 4. æœ€æ–°ä¸€æœŸæŒå€‰åˆ†å¸ƒé¤…åœ– (Bottom-Right)
        ax4 = fig.add_subplot(gs[1, 1])
        if not weights_df.empty:
            latest_weights = weights_df.iloc[-1]
            latest_holdings = latest_weights[latest_weights > 0.001] # Filter small holdings for clarity

            if not latest_holdings.empty:
                # Sort holdings by value for better visual hierarchy
                latest_holdings = latest_holdings.sort_values(ascending=False)
                
                pie_labels = latest_holdings.index
                pie_sizes = latest_holdings.values
                
                # Use a more visually appealing color palette
                colors = plt.cm.tab20c(np.linspace(0, 1, len(pie_labels)))
                
                # Explode the largest slice slightly
                explode = np.zeros(len(pie_labels))
                explode[0] = 0.1  # Explode largest slice
                
                wedges, texts, autotexts = ax4.pie(pie_sizes, 
                                                  labels=None, # Labels will be in legend
                                                  autopct='%1.1f%%', 
                                                  startangle=90, 
                                                  colors=colors,
                                                  pctdistance=0.85,
                                                  explode=explode,
                                                  shadow=False,
                                                  wedgeprops=dict(width=0.5, edgecolor='w', linewidth=2))

                ax4.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
                
                # Format the date for the title
                latest_date_str = weights_df.index[-1].strftime("%Y-%m-%d")
                ax4.set_title(f'æœ€æ–°æŒå€‰åˆ†å¸ƒ ({latest_date_str})', fontsize=15, pad=15, fontweight='bold')

                # Create a cleaner legend with percentage values
                legend_labels = [f'{label} ({size:.1%})' for label, size in zip(pie_labels, pie_sizes)]
                
                # Place legend to the right of the pie chart
                ax4.legend(wedges, legend_labels, 
                           title="æŒå€‰è³‡ç”¢",
                           loc="center left", 
                           bbox_to_anchor=(1.0, 0.5),
                           frameon=True,
                           fontsize=10,
                           title_fontsize=12)
                
                # Style the percentage text on the pie
                plt.setp(autotexts, size=10, weight="bold", color="white")

            else:
                ax4.text(0.5, 0.5, 'æœ€æ–°ä¸€æœŸç„¡æŒå€‰', 
                         horizontalalignment='center',
                         verticalalignment='center',
                         transform=ax4.transAxes,
                         fontsize=14)
        else:
            ax4.text(0.5, 0.5, 'ç„¡æŒå€‰æ•¸æ“š', 
                     horizontalalignment='center',
                     verticalalignment='center',
                     transform=ax4.transAxes,
                     fontsize=14)
        
        # èª¿æ•´æ•´é«”ä½ˆå±€
        fig.subplots_adjust(top=0.92, bottom=0.08, left=0.08, right=0.88)
        
        # ä¿å­˜åœ–ç‰‡
        plt.savefig('strategy_performance_enhanced_v3.png', dpi=300, bbox_inches='tight')
        print("\nå¢å¼·ç‰ˆç¸¾æ•ˆåœ–è¡¨å·²ä¿å­˜ç‚º strategy_performance_enhanced_v3.png")
        
        # å–®ç¨ä¿å­˜æœˆåº¦æ”¶ç›Šç†±åŠ›åœ–
        plt.figure(figsize=(12, 8))
        sns.heatmap(monthly_returns_pivot,
                    annot=True,
                    fmt='.1%',
                    cmap='RdYlGn',
                    center=0,
                    cbar_kws={'label': 'æœˆåº¦æ”¶ç›Šç‡'})
        plt.title('æœˆåº¦æ”¶ç›Šç†±åŠ›åœ–', pad=20)
        plt.tight_layout()
        plt.savefig('monthly_returns_heatmap_v3.png', dpi=300, bbox_inches='tight')
        print("æœˆåº¦æ”¶ç›Šç†±åŠ›åœ–å·²ä¿å­˜ç‚º monthly_returns_heatmap_v3.png")
        
        plt.show()

    except ImportError:
        print("\nè­¦å‘Šï¼šæœªå®‰è£å¿…è¦çš„å¥—ä»¶ï¼Œè«‹åŸ·è¡Œï¼š")
        print("pip install matplotlib seaborn")
    except Exception as e:
        print(f"\nç¹ªè£½åœ–è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # --- æ­¥é©Ÿ 8: å°‡çµæœè¼¸å‡ºè‡³Excelæ–‡ä»¶ ---
    print("\næ­¥é©Ÿ 8: å°‡çµæœè¼¸å‡ºè‡³Excelæ–‡ä»¶...")
    try:
        print("\næª¢æŸ¥ portfolio_value_over_time:")
        print(portfolio_value_over_time)
        print("\næª¢æŸ¥ weights_df:")
        print(weights_df)
        print("\næª¢æŸ¥ performance_summary:")
        print(performance_summary)

        # Construct filename based on strategy components
        factor_suffix = "_Enhanced" if config.use_enhanced_factor else "_Original"
        hedge_suffix = f"_NDXShort{int(config.ndx_short_ratio*100)}pct" if config.apply_ndx_short_hedge else ""
        excel_filename = f'Momentum_Backtest_Results_{config.weighting_method}{factor_suffix}{hedge_suffix}.xlsx'
        with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
            # å°‡æŠ•è³‡çµ„åˆæ·¨å€¼ä¿å­˜åˆ°ç¬¬ä¸€å€‹sheet
            pd.DataFrame(portfolio_value_over_time).to_excel(writer, sheet_name='Portfolio_Value', index_label='Date')

            # å°‡æ¬Šé‡è¨˜éŒ„ä¿å­˜åˆ°ç¬¬äºŒå€‹sheet
            weights_df.to_excel(writer, sheet_name='Rebalance_Weights', index_label='Rebalance_Date')

            # å°‡ç¸¾æ•ˆæŒ‡æ¨™ä¿å­˜åˆ°ç¬¬ä¸‰å€‹sheet
            pd.DataFrame(list(performance_summary.items()), columns=['Metric', 'Value']).to_excel(
                writer, sheet_name='Performance', index=False)

        print("çµæœå·²æˆåŠŸå°å‡ºè‡³", excel_filename)
        print("å·¥ä½œè¡¨å…§å®¹:")
        print("1. Portfolio_Value - æŠ•è³‡çµ„åˆæ¯æ—¥æ·¨å€¼")
        print("2. Rebalance_Weights - èª¿å€‰æ—¥æ¬Šé‡é…ç½®")
        print("3. Performance - ç¸¾æ•ˆæŒ‡æ¨™åŒ¯ç¸½")

    except ModuleNotFoundError:
        print("éŒ¯èª¤ï¼šç¼ºå°‘openpyxlå¥—ä»¶ï¼Œè«‹åŸ·è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£ï¼š")
        print("pip install openpyxl")
    except Exception as e:
        print(f"å°å‡ºExcelæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

    # æŸ¥çœ‹æœ€è¿‘ä¸€æœŸçš„æŒå€‰
    if not weights_df.empty:
        try:
            # Get the last rebalancing date from the weights_df index
            latest_rebal_date = weights_df.index[-1]
            
            selected_weights = weights_df.loc[latest_rebal_date]
            holdings = selected_weights[selected_weights > 0].sort_values(ascending=False)
            print(f"\n{latest_rebal_date.date()} (æœ€è¿‘ä¸€æœŸ) æŒå€‰ ({config.weighting_method.replace('_', ' ').title()} Weighting):")
            if not holdings.empty:
                print(holdings)
            else:
                print("ç„¡æŒå€‰ã€‚")

        except IndexError:
            print("\nç„¡æ³•ç²å–æœ€è¿‘çš„èª¿å€‰æ—¥ï¼Œæ¬Šé‡è¨˜éŒ„å¯èƒ½ç‚ºç©ºæˆ–ç´¢å¼•éŒ¯èª¤ã€‚")
        except Exception as e:
            print(f"\næŸ¥è©¢æœ€è¿‘ä¸€æœŸæŒå€‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    else:
        print("\næ¬Šé‡è¨˜éŒ„ç‚ºç©ºï¼Œç„¡æ³•æŸ¥è©¢æœ€è¿‘ä¸€æœŸæŒå€‰ã€‚")

    return performance_summary